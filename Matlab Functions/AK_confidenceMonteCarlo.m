function [ alphaOptim, expectedConfidence, simulatedConfidence, simulation] = AK_confidenceMonteCarlo( intensity, reportedConfidence, perceptNoise,...
    nTrials, decisionCriterion, possibleConfidenceValues )
%This is an implementation of the confidence fitness algorithm transcribed from Sanders et al. (2016),
% https://www.cell.com/neuron/pdfExtended/S0896-6273(16)30016-2). 
%Alex Kale (kalea@uw.edu) wrote this code for modeling confidence data in the IEEE InfoVis 2018 submission
% "Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data".
%   INPUT
%       intensity: a vector of stimulus intensities shown to the participant on each trial
%       reportedConfidence: a vector of reported confidence ratings from the participant on each trial
%       perceptNoise: an estimate of the noise in perceptual decision-making; the spread parameter of a 
%           cumulative Gaussian psychometric function fit to participant responses on an 2AFC task
%       nTrials: the number of stimulated trials in the Monte Carlo simulation
%       decisionCriterion: the level of stimulus intensity corresponding to zero information about 2AFC task;
%           this point demarcates whether the evidence provided is in favor of one alternative or the other
%       possibleConfidenceValues: a vector of all possible confidence values; the scale used to elicit confidence responses
%       OUTPUT
%           alphaOptim: the optimal value of confidence fitness returned by the maximum likelihood fitting procedure
%           expectedConfidence: a vector of the confidence ratings predicted by the model for each trial in 'intensity' 
%               using the optimized level of confidence fitness
%           simulatedConfidence: a vector of confidence ratings predicted by the model for each trial in 'intensity'
%               assuming perfect confidence reporting (alpha=1); these are the confidence estimates given by the Monte Carlo
%               simulation of the ideal observer with no noise in confidence reporting
%           simulation: a structure containing simulated trials, including stimulus intensities and simulated percepts used to model confidence


% check input
if nargin < 3 || length(intensity) ~= length(reportedConfidence)
    error('AK_confidenceMonteCarlo requires as input: a vector of stimulus intensities across trials; a vector of reported confidence ratings on each trial; and an estimate of perceptual noise (the slope param of the PF)');
end
if nargin < 4 
    % default to 10000000 simulation trials, decision criterion of zero, and confidence ratings from 50 to 100 (for Jobs Report study)
%     nTrials = 10000000;
    nTrials = 2000;
    decisionCriterion = 0;
    possibleConfidenceValues = 50:100;
end

% generate simulation sample: 
% center discriminabilities around zero,
% sample between positive and negative of greatest intensity shown on a single trial
% use intensities sampled with user in simulation
intensity = intensity - decisionCriterion;
if max(intensity) > abs(min(intensity))
    maxIntensity = max(intensity);
else
    maxIntensity = abs(min(intensity));
end
intensityList = unique(intensity); % used in mixing parameter optimization
discriminability = [intensityList; maxIntensity .* (2 .* rand(nTrials - length(intensityList), 1) - 1)]; % use sampled values in Monte Carlo simulation 

% Monte Carlo simulation of percepts, responses, and correctness:
% model Gaussian noise in perception
noise = normrnd(0,perceptNoise,[nTrials 1]); 
% generate percepts
percept = discriminability + noise; 
% scoring modeled perceptual decisions
correct = sign(percept .* discriminability); % the sign of the product will only be negative if the percept is wrong
correct(correct==-1) = 0; % change from 1 & -1 to logical index
correct = logical(correct);

% bin mean correctness by discriminability to get confidence:
% sort values into 200 bins of equal size
binEdges = linspace(-maxIntensity, maxIntensity, 201); % create linearly spaced bin edge vector
% preallocate variables for speed
perceptBinIdx = zeros(length(percept),1); 
confidenceHist = zeros(length(binEdges) - 1, 1);
for iBin = 1:length(binEdges) - 1
    % logical index of all percepts in this bin
    if iBin == 1 % catch percepts below -maxIntensity by not placing lower bound
        binIdx = percept <= binEdges(iBin + 1);
    elseif iBin == length(binEdges) - 1 % catch percepts above maxIntensity by not placing upper bound
        binIdx = binEdges(iBin) <= percept;
    else % does percept fall inside of this bin?
        binIdx = binEdges(iBin) <= percept & percept <= binEdges(iBin + 1);
    end
    % assign bin index value for each percept generated by the simulation
    perceptBinIdx(binIdx) = iBin;
    % calculate confidence per bin
    confidenceHist(iBin) = mean(correct(binIdx));
end

% assign a continuous confidence rating to each percept simulated
perceptConfidence = confidenceHist(perceptBinIdx);

% discreteize confidence per simulated percept to match the rate of use of reported confidence units for this data set:
% preallocate
ratingFreq = zeros(size(possibleConfidenceValues));
perceptConfidenceDiscrete = zeros(size(perceptConfidence));
for iC = length(possibleConfidenceValues):-1:1; % decrementing loop
    % determine cumulative frequencey of reported confidence relative to overall number of ratings
    ratingFreq(iC) = sum(reportedConfidence <= possibleConfidenceValues(iC)) / length(reportedConfidence);
    % fill in discrete confidence values at or below this percentile
    perceptConfidenceDiscrete(perceptConfidence <= quantile(perceptConfidence, ratingFreq(iC))) = possibleConfidenceValues(iC);
end

% prepare indices for confidenceProbabilityTable per trial
intensityTrialIdx = arrayfun(@(x) find(x == intensityList), intensity); % index in intesityList of each intensity sampled
reportedConfidenceTrialIdx = arrayfun(@(x) find(x == possibleConfidenceValues), reportedConfidence); % index in list of possibleConfidenceValues of each reportedConfidence value

% find optimal mixing parameter to represent extent to which users report statistical confidence vs random confidence
alphaOptim = fmincon(@logLikelihoodOfAlpha, 0.5, [], [], [], [], 0, 1); % univariate optimization of alpha, starting at 0.5 and bounded between 0 and 1 

% estimate confidence for each stimulus based on optimal mixing parameter
probabilityExpected = confidenceReportingModel(alphaOptim); % table of probability of each level of confidence at each level of intensity, given alphaOptim
expectedConfidence = sum(probabilityExpected(intensityTrialIdx,:) * possibleConfidenceValues', 2); % the expected value of confidence on each trial (the sum of confidence values weighted by their probability given alpha)

% estimate confidence for each stimulus based on ideal confidence reporting
probabilityIdeal = confidenceReportingModel(1); % table of probability of each level of confidence at each level of intensity, given alpha = 1 (perfect confidence reporting)
simulatedConfidence = sum(probabilityIdeal(intensityTrialIdx,:) * possibleConfidenceValues', 2); % the expected value of confidence on each trial (the sum of confidence values weighted by their probability given alpha)

% format simulated data for output
simulation.discriminability = discriminability;
simulation.percept = percept;
simulation.correct = correct;
simulation.confidence = perceptConfidenceDiscrete;

    % returns the negative log likelihood of user responses given the mixing parameter alpha and the simulated distribution of confidence ratings
    function LL = logLikelihoodOfAlpha(alpha)
        % get probability table for intensity-by-confidence rating
        probabilityTable = confidenceReportingModel(alpha);
        % calculate the negative log likelihood of user responses given the mixing parameter alpha and the simulated distribution of confidence ratings 
        LL = -sum(sum(log(probabilityTable(intensityTrialIdx, reportedConfidenceTrialIdx))));
    end
    
    % create lookup table for the probability of reporting each confidence at each stimulus intensity sampled
    function confidenceProbabilityTable = confidenceReportingModel(alpha)
        % simulate estimated confidence at each percept given a distribution of "noise-free" confidence ratings and a mixing parameter: alpha
        randC = randi([1 length(perceptConfidenceDiscrete)],length(percept),1);
        estimatedConfidence = round((alpha .* perceptConfidenceDiscrete) + ((1 - alpha) .* perceptConfidenceDiscrete(randC)));
        % create probability table for intensity-by-confidence rating
        confidenceProbabilityTable = zeros(length(intensityList),length(possibleConfidenceValues)); % preallocate
        for iInt = 1:length(intensityList)
            % index for simulated percepts matching this stimulus intensity:
            % match if this is the closest intensity to the percept
            % test without indexing errors
            if iInt == 1
                intensityIdx = abs(percept - intensityList(iInt)) < abs(percept - intensityList(iInt + 1));
            elseif iInt == length(intensityList)
                intensityIdx = abs(percept - intensityList(iInt)) < abs(percept - intensityList(iInt - 1));
            else
                intensityIdx = abs(percept - intensityList(iInt)) < abs(percept - intensityList(iInt - 1)) & abs(percept - intensityList(iInt)) < abs(percept - intensityList(iInt + 1));
            end
            for iConf = 1:length(possibleConfidenceValues)
                % index for estimatedConfidence matching this confidence rating
                confidenceIdx = estimatedConfidence == possibleConfidenceValues(iConf);
                % fill in probability table:
                % proportion of simulated trials at this intensity for which this level of confidence was estimated using the cureent level of alpha
                confidenceProbabilityTable(iInt,iConf) = sum(intensityIdx & confidenceIdx) / sum(intensityIdx); 
            end
        end
        % replace nans with zeros
        confidenceProbabilityTable(isnan(confidenceProbabilityTable)) = 0;
        % hack the probabilityTable so that there are no values equal to zero or 1 
        % (because log(0) = -inf and because the probability of a reported confidence value is never really zero)
        confidenceProbabilityTable(confidenceProbabilityTable == 0) = 0.001;
        confidenceProbabilityTable(confidenceProbabilityTable == 1) = 0.999;
    end

end

